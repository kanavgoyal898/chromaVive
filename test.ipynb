{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **chromaVive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "As individuals with limited GPU power and computational resources, it is not feasible for us to replicate the extensive work done by Richard Zhang et al. in their seminal paper *\"Colorful Image Colorization\"* (ECCV 2016). However, we provide a **proof of concept** to demonstrate the fundamental approach to tackling the image colorization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Color Space Conversion:** RGB & LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = 'image.jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Original Image:* BGR to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(IMG_PATH)\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Original Image:* BGR to LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(IMG_PATH)\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "L, a, b = cv.split(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *LAB Color Space:* Lightness (L), Green-Red (a), Blue-Yellow (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(L, cmap='binary')\n",
    "ax[0].set_title('L Channel')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(a, cmap='Reds')\n",
    "ax[1].set_title('a Channel')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(b, cmap='Blues')\n",
    "ax[2].set_title('b Channel')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *LAB Color Space:* Lightness (L), Green-Red-Blue-Yellow (ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].imshow(L, cmap='gray')\n",
    "ax[0].set_title('L Channel')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(cv.merge([np.zeros_like(L), a, b]), cmap='viridis')\n",
    "ax[1].set_title('ab Channels')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_img = cv.cvtColor(cv.merge([L, a, b]), cv.COLOR_LAB2RGB)\n",
    "plt.imshow(merged_img)\n",
    "plt.title('Original (LAB to RGB) Image')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bin Classification:** AB Color Space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "grid_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin Classification: a and b channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ab_bins(grid_size=16):\n",
    "    a_range = torch.arange(-128, 128, grid_size)\n",
    "    b_range = torch.arange(-128, 128, grid_size)\n",
    "    ab_bins = torch.tensor([[a, b] for a in a_range for b in b_range])\n",
    "\n",
    "    return ab_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_bins = create_ab_bins(grid_size)\n",
    "print(f'No. of bins: {ab_bins.shape[0]}')\n",
    "print(f'ab_bins shape: {ab_bins.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *AB Bin Classification:* Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ab_bins[:, 0], ab_bins[:, 1], 'o')\n",
    "plt.xlabel('a channel')\n",
    "plt.ylabel('b channel')\n",
    "plt.title('a-b bins')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *K-nearest bins*: Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(ab_target, ab_reference, k=5):\n",
    "    \"\"\"\n",
    "    Find the k nearest neighbors in the ab color space to a target point.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    ab_target : torch.Tensor\n",
    "        Target point in the form of (a, b).\n",
    "\n",
    "    ab_reference : torch.Tensor\n",
    "        Reference points, shape (n, 2).\n",
    "\n",
    "    k : int, optional\n",
    "        Number of nearest neighbors to find (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        k nearest points in the ab color space.\n",
    "\n",
    "    torch.Tensor\n",
    "        Distances of the k nearest points from the target.\n",
    "    \"\"\"\n",
    "\n",
    "    ab_target = ab_target.float()\n",
    "    ab_reference = ab_reference.float()\n",
    "\n",
    "    distances = torch.linalg.norm(ab_reference - ab_target, dim=1)  # (n, ) L2 distances\n",
    "    k_distances = torch.argsort(distances)[:k]\n",
    "    return k_distances, distances[k_distances]\n",
    "\n",
    "def gaussian_encoding(ab_target, ab_reference, k=5, std_dev=5.0):\n",
    "    \"\"\"\n",
    "    Calculate Gaussian weights for ab_reference based on distance to ab_target.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    ab_target : torch.Tensor\n",
    "        Target point in the form of (a, b).\n",
    "\n",
    "    ab_reference : torch.Tensor\n",
    "        Reference points, shape (n, 2).\n",
    "\n",
    "    std_dev : float, optional\n",
    "        Standard deviation for the Gaussian distribution (default is 5.0).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Normalized Gaussian weights for each reference point.\n",
    "    \"\"\"\n",
    "    \n",
    "    k_distances_indices, k_distance_values = k_nearest_neighbours(ab_target, ab_reference, k)\n",
    "    weights = torch.exp(-0.5 * (k_distance_values / std_dev) ** 2)  # (k, ) gaussian encoding                  \n",
    "    soft_weights = weights / torch.sum(weights)                     # (k, ) normalized weights\n",
    "\n",
    "    n = ab_reference.shape[0]\n",
    "    soft_weights_encoded = torch.zeros(n)                           # (n, ) encoded weights\n",
    "    soft_weights_encoded[k_distances_indices] = soft_weights\n",
    "    return soft_weights_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_target = torch.randint(-128, 128, (2,), dtype=torch.float32)\n",
    "soft_encoded_weights = gaussian_encoding(ab_target, ab_bins, k)\n",
    "soft_encoded_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sum of weights: {soft_encoded_weights.sum():.4f}')\n",
    "print(f'Max weight: {soft_encoded_weights.max():.4f}')\n",
    "print(f'Min weight: {soft_encoded_weights.min():.4f}')\n",
    "print(f'Soft Encoded Weights\\' shape: {soft_encoded_weights.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *K-nearest bins*: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 16))\n",
    "plt.scatter(ab_bins[:, 0], ab_bins[:, 1], color='blue', s=50)\n",
    "plt.scatter(ab_target[0], ab_target[1], color='red', s=200)\n",
    "for i in range(len(ab_bins)):\n",
    "    plt.plot([ab_target[0], ab_bins[i, 0]], [ab_target[1], ab_bins[i, 1]], color='gray', linestyle='--') if soft_encoded_weights[i] > 0 else None\n",
    "plt.title('Distance from Target Point to ab_bins')\n",
    "plt.xlabel('a Channel')\n",
    "plt.ylabel('b Channel')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ImageNet**: Downscaled Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 8\n",
    "path = f'./datasets/ImageNet {img_size}X{img_size}/Imagenet#_train'\n",
    "extraction_path = f'datasets/extracted/LABEL/imagenet#_data_batch_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageNet Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_databatch(data_folder, idx, img_size=32):\n",
    "    data_file = os.path.join(data_folder, 'train_data_batch_')\n",
    "\n",
    "    d = unpickle(data_file + str(idx))\n",
    "    x = d['data']\n",
    "    y = d['labels']\n",
    "    mean_image = d['mean']\n",
    "\n",
    "    x = x/np.float32(255)\n",
    "    mean_image = mean_image/np.float32(255)\n",
    "\n",
    "    # Labels are indexed from 1, shift it so that indexes start at 0\n",
    "    y = [i-1 for i in y]\n",
    "    data_size = x.shape[0]\n",
    "\n",
    "    x -= mean_image\n",
    "\n",
    "    img_size2 = img_size * img_size\n",
    "\n",
    "    x = np.dstack((x[:, :img_size2], x[:, img_size2:2*img_size2], x[:, 2*img_size2:]))\n",
    "    x = x.reshape((x.shape[0], img_size, img_size, 3)).transpose(0, 3, 1, 2)\n",
    "\n",
    "    # create mirrored images\n",
    "    X_train = x[0:data_size, :, :, :]\n",
    "    Y_train = y[0:data_size]\n",
    "    X_train_flip = X_train[:, :, :, ::-1]\n",
    "    Y_train_flip = Y_train\n",
    "    X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "    Y_train = np.concatenate((Y_train, Y_train_flip), axis=0)\n",
    "\n",
    "    return dict(\n",
    "        X_train=X_train.astype('float32'),\n",
    "        Y_train=Y_train.astype('int32'),\n",
    "        mean=mean_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *ImageNet Local*: Inception & Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(10):\n",
    "    print(f'Loading batch {i+1}...')\n",
    "    data = load_databatch(path.replace('#', str(img_size)), i+1, img_size)\n",
    "\n",
    "    image_count = data['X_train'].shape[0]\n",
    "    print(f'Loaded batch: {i+1} with {image_count} images')\n",
    "\n",
    "    print('Saving data...')\n",
    "    np.save(f'{extraction_path.replace('#', str(img_size)).replace('LABEL', 'X_train')}{i+1}.npy', data['X_train'])     # X_train: (N, C, H, W)\n",
    "    np.save(f'{extraction_path.replace('#', str(img_size)).replace('LABEL', 'Y_train')}{i+1}.npy', data['Y_train'])     # Y_train: (N, )\n",
    "    np.save(f'{extraction_path.replace('#', str(img_size)).replace('LABEL', 'mean')}{i+1}.npy', data['mean'])           # mean: (C * H * W, )\n",
    "\n",
    "    count += image_count\n",
    "\n",
    "print(f'Total images: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_arrays(idx, img_size=img_size):\n",
    "    data = {}\n",
    "    data['X_train'] = np.load(f'{extraction_path.replace('#', str(img_size)).replace('LABEL', 'X_train')}{idx}.npy')\n",
    "    data['Y_train'] = np.load(f'{extraction_path.replace('#', str(img_size)).replace('LABEL', 'Y_train')}{idx}.npy')\n",
    "    data['mean'] = np.load(f'{extraction_path.replace('#', str(img_size)).replace('LABEL', 'mean')}{idx}.npy')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageNet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(1, 10)\n",
    "data = extract_arrays(idx, img_size)\n",
    "print('Data extracted from batch:', idx)\n",
    "data['X_train'].shape, data['Y_train'].shape, data['mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = data['X_train'].shape[0]\n",
    "index = random.randint(0, num_images-1)\n",
    "data['X_train'][index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data['X_train'][random.randint(0, num_images-1)].transpose(1, 2, 0)\n",
    "img = np.clip(img * 255 + 128, 0, 255).astype(np.uint8) # un-normalize\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Analysis:** Bin Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGB to LAB Color Space Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X_train'] = data['X_train'].transpose(0, 2, 3, 1)             # (N, C, H, W) -> (N, H, W, C)\n",
    "data['X_train'] = (data['X_train'] * 255 + 128).astype(np.uint8)    # un-normalize\n",
    "data['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_lab(img_batch):\n",
    "    N, H, W, C = img_batch.shape\n",
    "    if C != 3:\n",
    "        raise ValueError('Expected the last dimension to be 3 (RGB channels).')\n",
    "    \n",
    "    L_batch = []\n",
    "    a_batch = []\n",
    "    b_batch = []\n",
    "\n",
    "    for i in range(N):\n",
    "        lab_img = cv.cvtColor(img_batch[i], cv.COLOR_RGB2LAB)\n",
    "        L, a, b = cv.split(lab_img)\n",
    "        L_batch.append(L)\n",
    "        a_batch.append(a)\n",
    "        b_batch.append(b)\n",
    "\n",
    "    L_batch = np.array(L_batch)\n",
    "    a_batch = np.array(a_batch)\n",
    "    b_batch = np.array(b_batch)\n",
    "\n",
    "    return L_batch, a_batch, b_batch\n",
    "    \n",
    "L_batch, a_batch, b_batch = rgb_to_lab(data['X_train'])\n",
    "L_batch.shape, a_batch.shape, b_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ab(L_batch, a_batch, b_batch):\n",
    "    N, H, W = L_batch.shape\n",
    "    ab_batch = np.stack((a_batch, b_batch), axis=-1)\n",
    "\n",
    "    return L_batch, ab_batch\n",
    "\n",
    "L_batch, ab_batch = merge_ab(L_batch, a_batch, b_batch)\n",
    "L_batch.shape, ab_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_batch_flat = ab_batch.reshape(-1, 2)\n",
    "ab_batch_flat.shape    # (N * H * W, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cumulative Run:** Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_count = 0\n",
    "bin_counts = {}\n",
    "\n",
    "for ix in range(10):\n",
    "    print('Extracting data from batch:', ix+1)\n",
    "    print('---------------------------------')\n",
    "    print(ix)\n",
    "    data = extract_arrays(ix+1, img_size)\n",
    "    data['X_train'] = data['X_train'].transpose(0, 2, 3, 1)\n",
    "    data['X_train'] = (data['X_train'] * 255 + 128).astype(np.uint8)\n",
    "    \n",
    "    L_batch, a_batch, b_batch = rgb_to_lab(data['X_train'])\n",
    "    L_batch, ab_batch = merge_ab(L_batch, a_batch, b_batch)\n",
    "    ab_batch_flat = ab_batch.reshape(-1, 2)\n",
    "\n",
    "    num_pixels = ab_batch_flat.shape[0]\n",
    "    print(f'Number of pixels: {num_pixels} in {L_batch.shape[0]} images at {img_size}x{img_size} resolution.')\n",
    "    for i in range(num_pixels):\n",
    "        if i % L_batch.shape[0] == 0:\n",
    "            print(f'Processing pixel {i:8d}/{num_pixels:8d}... in batch {ix+1}')\n",
    "        torch_ab = torch.tensor(ab_batch_flat[i])\n",
    "        distance_key, _ = k_nearest_neighbours(torch_ab, ab_bins, 1)\n",
    "        nearest_bin = (ab_bins[distance_key[0]][0].item(), ab_bins[distance_key[0]][1].item())\n",
    "        bin_counts[nearest_bin] = bin_counts.get(nearest_bin, 0) + 1\n",
    "    \n",
    "    pixel_count += num_pixels\n",
    "    print('Extracted data from batch:', ix+1)\n",
    "    print('---------------------------------')\n",
    "\n",
    "print(f'Total pixels processed: {pixel_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cumulative Run:** Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_range = np.arange(-128, 128, grid_size)\n",
    "b_range = np.arange(-128, 128, grid_size)\n",
    "heatmap = np.zeros((len(a_range), len(b_range)))\n",
    "\n",
    "for (a, b), count in bin_counts.items():\n",
    "    a_index = (a + 128) // grid_size  \n",
    "    b_index = (b + 128) // grid_size  \n",
    "    heatmap[a_index, b_index] += count\n",
    "\n",
    "# log transform to make the heatmap more interpretable (ln(1+x))\n",
    "log_heatmap = np.log1p(heatmap)    \n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(log_heatmap, cmap='hsv', origin='lower', aspect='auto', interpolation='nearest')\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Pixel Count')\n",
    "\n",
    "plt.title('Pixel Distribution in AB Color Space Bins')\n",
    "plt.xlabel('B bins')\n",
    "plt.ylabel('A bins')\n",
    "plt.xticks(ticks=np.arange(len(b_range)), labels=b_range)\n",
    "plt.yticks(ticks=np.arange(len(a_range)), labels=a_range)\n",
    "\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
